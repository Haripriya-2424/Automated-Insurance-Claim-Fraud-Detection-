{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ff26c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "# Loading the dataset\n",
    "df = pd.read_csv(\"../data/data_with_anomalies.csv\")\n",
    "\n",
    "# Defining features and label\n",
    "X = df.drop(['claim_status', 'anomaly_flag'], axis=1)\n",
    "y = df['claim_status']\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Handling the class imbalance with SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_res, y_res = smote.fit_resample(X_scaled, y)\n",
    "\n",
    "# Split into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_res, y_res, test_size=0.2, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad375747",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Results\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.56      0.58     11072\n",
      "           1       0.58      0.61      0.60     10866\n",
      "\n",
      "    accuracy                           0.59     21938\n",
      "   macro avg       0.59      0.59      0.59     21938\n",
      "weighted avg       0.59      0.59      0.59     21938\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "lr_preds = lr.predict(X_test)\n",
    "lr_acc = accuracy_score(y_test, lr_preds)\n",
    "lr_f1 = f1_score(y_test, lr_preds)\n",
    "print(\"Logistic Regression Results\")\n",
    "print(classification_report(y_test, lr_preds))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d57ae8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Results\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.92      0.92     11072\n",
      "           1       0.92      0.92      0.92     10866\n",
      "\n",
      "    accuracy                           0.92     21938\n",
      "   macro avg       0.92      0.92      0.92     21938\n",
      "weighted avg       0.92      0.92      0.92     21938\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train, y_train)\n",
    "rf_preds = rf.predict(X_test)\n",
    "rf_acc = accuracy_score(y_test, rf_preds)\n",
    "rf_f1 = f1_score(y_test, rf_preds)\n",
    "print(\"Random Forest Results\")\n",
    "print(classification_report(y_test, rf_preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "99e423fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Results\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.98      0.93     11072\n",
      "           1       0.98      0.87      0.92     10866\n",
      "\n",
      "    accuracy                           0.93     21938\n",
      "   macro avg       0.93      0.93      0.93     21938\n",
      "weighted avg       0.93      0.93      0.93     21938\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# XGBoost\n",
    "xgb = XGBClassifier(eval_metric='logloss')\n",
    "xgb.fit(X_train, y_train)\n",
    "xgb_preds = xgb.predict(X_test)\n",
    "xgb_acc = accuracy_score(y_test, xgb_preds)\n",
    "xgb_f1 = f1_score(y_test, xgb_preds)\n",
    "print(\"XGBoost Results\")\n",
    "print(classification_report(y_test, xgb_preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a79e220",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Model Comparison:\n",
      "Logistic Regression - Accuracy: 0.5885, F1 Score: 0.5959\n",
      "Random Forest       - Accuracy: 0.9187, F1 Score: 0.9179\n",
      "XGBoost             - Accuracy: 0.9285, F1 Score: 0.9235\n"
     ]
    }
   ],
   "source": [
    "# Model comparison\n",
    "print(\" Model Comparison:\")\n",
    "print(f\"Logistic Regression - Accuracy: {lr_acc:.4f}, F1 Score: {lr_f1:.4f}\")\n",
    "print(f\"Random Forest       - Accuracy: {rf_acc:.4f}, F1 Score: {rf_f1:.4f}\")\n",
    "print(f\"XGBoost             - Accuracy: {xgb_acc:.4f}, F1 Score: {xgb_f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8206b296",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Best Model Based on F1 Score: XGBoost (0.9235)\n"
     ]
    }
   ],
   "source": [
    "# Finding the best model\n",
    "best_model = max([\n",
    "    (\"Logistic Regression\", lr_f1),\n",
    "    (\"Random Forest\", rf_f1),\n",
    "    (\"XGBoost\", xgb_f1)\n",
    "], key=lambda x: x[1])\n",
    "\n",
    "print(f\"\\n Best Model Based on F1 Score: {best_model[0]} ({best_model[1]:.4f})\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
